# -*- coding: utf-8 -*-
"""dataAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xxB1-nLt5ZuKB-6POH8sz5-xYJblKXZ4

#                      PARSER
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import csv
# %matplotlib inline

def parse_if_number(s):
  try:
      return float(s)
  except:
      return True if s == "true" else False if s == "false" else s if s else None


def parse_ndarray(s):
  print(s)
  return np.fromstring(s, sep=' ') if s else None


def parse_name_attr(s):
  return s.split(':')[0] if s else None


def parse_run(s):
  return int(s.split('-')[2]) if s else None


def vector_parse():
  path_csv = "non-monitoring-10s.csv"

  # vec files are huge, try to reduce their size ASAP!!
  data = pd.read_csv(path_csv,
                    delimiter=",", encoding='utf-8',
                    usecols=['run', 'type', 'module', 'name', 'vecvalue', 'vectime'],
                    converters={
                        'run': parse_run,
                        'vectime': parse_ndarray,  # i guess
                        'vecvalue': parse_ndarray,
                        'name': parse_name_attr
                    }, engine='python', error_bad_lines=False
                    )
 

  # remove useless rows
  data = data[data.type == 'vector']
  data.reset_index(inplace=True, drop=True)

  # rename vecvalue for simplicity...
  data = data.rename({'vecvalue': 'value', 'vectime': 'time'}, axis=1)
  return data[['run', 'name', 'time', 'value']].sort_values(['run', 'name'])

import sys
import csv

csv.field_size_limit(sys.maxsize)
new_df = []

def main():
    print("\n\nPerformance Evaluation - Python Data Analysis\n")
    df = vector_parse()
    print(df)
    
if __name__ == '__main__':
    main()